{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "919ed7eb-796f-48fe-b5ce-3e8ae21a3974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed66902d-52a5-4b2d-81a8-f2e8beb20ea3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fashion-mnist\n",
      "           dataset  scale       algorithm   throughput    recall  cakes_alg\n",
      "316  fashion-mnist    1.0           annoy  2191.849364  0.949727      False\n",
      "347  fashion-mnist    1.0      faiss-flat   212.602278  1.000000      False\n",
      "354  fashion-mnist    1.0  faiss-ivf-flat  2009.483440  1.000000      False\n",
      "           dataset  scale       algorithm   throughput    recall  cakes_alg\n",
      "302  fashion-mnist    2.0           annoy  2118.513407  0.926636      False\n",
      "376  fashion-mnist    2.0      faiss-flat   106.372153  1.000000      False\n",
      "379  fashion-mnist    2.0  faiss-ivf-flat   939.169025  0.999909      False\n",
      "           dataset  scale       algorithm   throughput    recall  cakes_alg\n",
      "323  fashion-mnist    4.0           annoy  2043.628270  0.897667      False\n",
      "352  fashion-mnist    4.0      faiss-flat    53.077121  1.000000      False\n",
      "344  fashion-mnist    4.0  faiss-ivf-flat   461.015818  0.996833      False\n",
      "           dataset  scale       algorithm   throughput    recall  cakes_alg\n",
      "369  fashion-mnist    8.0           annoy  1925.592809  0.857333      False\n",
      "340  fashion-mnist    8.0      faiss-flat    26.577270  1.000000      False\n",
      "329  fashion-mnist    8.0  faiss-ivf-flat   225.827100  0.995333      False\n",
      "           dataset  scale       algorithm   throughput  recall  cakes_alg\n",
      "375  fashion-mnist   16.0           annoy  1841.862831  0.8615      False\n",
      "371  fashion-mnist   16.0      faiss-flat    13.292249  1.0000      False\n",
      "295  fashion-mnist   16.0  faiss-ivf-flat   116.960148  0.9910      False\n",
      "           dataset  scale       algorithm   throughput  recall  cakes_alg\n",
      "310  fashion-mnist   32.0           annoy  1850.942695   0.775      False\n",
      "308  fashion-mnist   32.0      faiss-flat     6.647092   1.000      False\n",
      "385  fashion-mnist   32.0  faiss-ivf-flat    59.147868   0.985      False\n",
      "           dataset  scale       algorithm   throughput  recall  cakes_alg\n",
      "280  fashion-mnist   64.0           annoy  1787.142346   0.677      False\n",
      "285  fashion-mnist   64.0      faiss-flat     3.323591   1.000      False\n",
      "370  fashion-mnist   64.0  faiss-ivf-flat    26.068382   0.968      False\n",
      "           dataset  scale       algorithm   throughput  recall  cakes_alg\n",
      "282  fashion-mnist  128.0           annoy  1659.660152   0.538      False\n",
      "337  fashion-mnist  128.0      faiss-flat     1.661720   1.000      False\n",
      "284  fashion-mnist  128.0  faiss-ivf-flat    13.265281   0.964      False\n",
      "           dataset  scale       algorithm   throughput  recall  cakes_alg\n",
      "304  fashion-mnist  256.0           annoy  1597.263598   0.592      False\n",
      "322  fashion-mnist  256.0      faiss-flat     0.830801   1.000      False\n",
      "300  fashion-mnist  256.0  faiss-ivf-flat     6.650268   0.962      False\n",
      "           dataset  scale       algorithm   throughput  recall  cakes_alg\n",
      "350  fashion-mnist  512.0           annoy  1826.362496   0.581      False\n",
      "378  fashion-mnist  512.0      faiss-flat     0.415544   1.000      False\n",
      "351  fashion-mnist  512.0  faiss-ivf-flat     3.562712   0.949      False\n",
      "\\begin{tabular}{rrrrrrrrr}\n",
      "\\toprule\n",
      "scaling-factor & faiss-ivf-flat(QPS) & faiss-ivf-flat(R) & faiss-flat(QPS) & faiss-flat(R) & annoy(QPS) & annoy(R) & CAKES(QPS) & CAKES(R) \\\\\n",
      "\\midrule\n",
      "1.000 & 2191.849 & 0.950 & 212.602 & 1.000 & 2009.483 & 1.000 & 2167.365 & 1.000 \\\\\n",
      "2.000 & 2118.513 & 0.927 & 106.372 & 1.000 & 939.169 & 1.000 & 1141.225 & 1.000 \\\\\n",
      "4.000 & 2043.628 & 0.898 & 53.077 & 1.000 & 461.016 & 0.997 & 982.117 & 1.000 \\\\\n",
      "8.000 & 1925.593 & 0.857 & 26.577 & 1.000 & 225.827 & 0.995 & 1179.813 & 1.000 \\\\\n",
      "16.000 & 1841.863 & 0.862 & 13.292 & 1.000 & 116.960 & 0.991 & 1201.409 & 1.000 \\\\\n",
      "32.000 & 1850.943 & 0.775 & 6.647 & 1.000 & 59.148 & 0.985 & 1157.667 & 1.000 \\\\\n",
      "64.000 & 1787.142 & 0.677 & 3.324 & 1.000 & 26.068 & 0.968 & 1102.849 & 1.000 \\\\\n",
      "128.000 & 1659.660 & 0.538 & 1.662 & 1.000 & 13.265 & 0.964 & 1039.607 & 1.000 \\\\\n",
      "256.000 & 1597.264 & 0.592 & 0.831 & 1.000 & 6.650 & 0.962 & 1058.972 & 1.000 \\\\\n",
      "512.000 & 1826.362 & 0.581 & 0.416 & 1.000 & 3.563 & 0.949 & 1035.260 & 1.000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "glove-25\n",
      "\\begin{tabular}{rrrrrrrrr}\n",
      "\\toprule\n",
      "scaling-factor & faiss-ivf-flat(QPS) & faiss-ivf-flat(R) & faiss-flat(QPS) & faiss-flat(R) & annoy(QPS) & annoy(R) & CAKES(QPS) & CAKES(R) \\\\\n",
      "\\midrule\n",
      "1.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 722.326 & 1.000 \\\\\n",
      "2.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 574.516 & 1.000 \\\\\n",
      "4.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 625.208 & 1.000 \\\\\n",
      "8.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 592.699 & 1.000 \\\\\n",
      "16.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 549.073 & 1.000 \\\\\n",
      "32.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 475.266 & 1.000 \\\\\n",
      "64.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 461.066 & 1.000 \\\\\n",
      "128.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 440.758 & 1.000 \\\\\n",
      "256.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 422.591 & 1.000 \\\\\n",
      "0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "random-1000000-128\n",
      "\\begin{tabular}{rrrrrrrrr}\n",
      "\\toprule\n",
      "scaling-factor & faiss-ivf-flat(QPS) & faiss-ivf-flat(R) & faiss-flat(QPS) & faiss-flat(R) & annoy(QPS) & annoy(R) & CAKES(QPS) & CAKES(R) \\\\\n",
      "\\midrule\n",
      "1.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 535.499 & 1.000 \\\\\n",
      "0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\\\\n",
      "0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\\\\n",
      "0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\\\\n",
      "0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\\\\n",
      "0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\\\\n",
      "0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\\\\n",
      "0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\\\\n",
      "0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\\\\n",
      "0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "sift\n",
      "    dataset  scale       algorithm   throughput   recall  cakes_alg\n",
      "311    sift    1.0           annoy  3977.431514  0.68625      False\n",
      "281    sift    1.0      faiss-flat    72.609820  1.00000      False\n",
      "334    sift    1.0  faiss-ivf-flat   697.809018  1.00000      False\n",
      "    dataset  scale       algorithm   throughput   recall  cakes_alg\n",
      "297    sift    2.0           annoy  3800.400786  0.61425      False\n",
      "330    sift    2.0      faiss-flat    36.236827  1.00000      False\n",
      "283    sift    2.0  faiss-ivf-flat   329.950279  1.00000      False\n",
      "    dataset  scale       algorithm   throughput  recall  cakes_alg\n",
      "320    sift    4.0           annoy  3686.605518  0.6370      False\n",
      "288    sift    4.0      faiss-flat    18.152236  1.0000      False\n",
      "343    sift    4.0  faiss-ivf-flat   165.175217  0.9995      False\n",
      "    dataset  scale       algorithm   throughput  recall  cakes_alg\n",
      "367    sift    8.0           annoy  3582.099351    0.71      False\n",
      "380    sift    8.0      faiss-flat     9.077251    1.00      False\n",
      "356    sift    8.0  faiss-ivf-flat    77.186506    1.00      False\n",
      "    dataset  scale       algorithm   throughput  recall  cakes_alg\n",
      "364    sift   16.0           annoy  3498.893271    0.69      False\n",
      "381    sift   16.0      faiss-flat     4.539204    1.00      False\n",
      "359    sift   16.0  faiss-ivf-flat    39.809366    1.00      False\n",
      "    dataset  scale       algorithm   throughput  recall  cakes_alg\n",
      "319    sift   32.0           annoy  3435.058161   0.639      False\n",
      "287    sift   32.0      faiss-flat     2.268823   1.000      False\n",
      "341    sift   32.0  faiss-ivf-flat    20.909545   0.999      False\n",
      "    dataset  scale       algorithm   throughput  recall  cakes_alg\n",
      "339    sift   64.0           annoy  3391.915749   0.678      False\n",
      "299    sift   64.0      faiss-flat     1.135344   1.000      False\n",
      "312    sift   64.0  faiss-ivf-flat     8.867212   0.997      False\n",
      "    dataset  scale       algorithm  throughput  recall  cakes_alg\n",
      "358    sift  128.0      faiss-flat    0.565846   1.000      False\n",
      "301    sift  128.0  faiss-ivf-flat    4.786171   0.993      False\n",
      "\\begin{tabular}{rrrrrrrrr}\n",
      "\\toprule\n",
      "scaling-factor & faiss-ivf-flat(QPS) & faiss-ivf-flat(R) & faiss-flat(QPS) & faiss-flat(R) & annoy(QPS) & annoy(R) & CAKES(QPS) & CAKES(R) \\\\\n",
      "\\midrule\n",
      "1.000 & 3977.432 & 0.686 & 72.610 & 1.000 & 697.809 & 1.000 & 551.894 & 1.000 \\\\\n",
      "2.000 & 3800.401 & 0.614 & 36.237 & 1.000 & 329.950 & 1.000 & 265.615 & 1.000 \\\\\n",
      "4.000 & 3686.606 & 0.637 & 18.152 & 1.000 & 165.175 & 1.000 & 142.545 & 1.000 \\\\\n",
      "8.000 & 3582.099 & 0.710 & 9.077 & 1.000 & 77.187 & 1.000 & 79.353 & 1.000 \\\\\n",
      "16.000 & 3498.893 & 0.690 & 4.539 & 1.000 & 39.809 & 1.000 & 81.172 & 1.000 \\\\\n",
      "32.000 & 3435.058 & 0.639 & 2.269 & 1.000 & 20.910 & 0.999 & 78.124 & 1.000 \\\\\n",
      "64.000 & 3391.916 & 0.678 & 1.135 & 1.000 & 8.867 & 0.997 & 74.344 & 1.000 \\\\\n",
      "128.000 & 0.566 & 1.000 & 4.786 & 0.993 & 0.000 & 0.000 & 68.005 & 1.000 \\\\\n",
      "0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\\\\n",
      "0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('scaling-results.csv')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to determine if row contains data for a CAKES algorithm or a rival algorithm\n",
    "def cakes_alg(row): \n",
    "    if row['algorithm'] in ['GreedySieve', 'Sieve', 'SieveSepCenter', 'RepeatedRnn', 'Linear']: \n",
    "        return True \n",
    "    else: \n",
    "        return False\n",
    "\n",
    "\n",
    "def alg_order(col): \n",
    "    match col:\n",
    "        case 'faiss-ivf-flat':\n",
    "            return 0\n",
    "        case 'faiss-flat':\n",
    "            return 1\n",
    "        case 'annoy':\n",
    "            return 2\n",
    "        case 'CAKES':\n",
    "            return 3\n",
    "\n",
    "\n",
    "# Temporary field to allow sorting by on CAKES vs non-CAKES \n",
    "df['cakes_alg'] = df.apply(cakes_alg, axis =1)\n",
    "\n",
    "# We only want k == 10 here\n",
    "df = df[df.k == 10]\n",
    "\n",
    "# Get rid of unnecessary columns \n",
    "df.drop(columns = ['metric', 'cardinality', 'dimensionality', 'tuning_time', 'index_build_time', 'k'], inplace = True)\n",
    "\n",
    "# Sometimes the 1 multiplier rows got screwed up \n",
    "df = df.fillna(1.0)\n",
    "\n",
    "# This is what we ultimately want as columns in the tables \n",
    "# Really, we want to have split columns for each algorithm, but my brain is too small to do that here\n",
    "# so I am just going to condense by hand later\n",
    "columns = ['scaling-factor', 'faiss-ivf-flat(QPS)', 'faiss-ivf-flat(R)', 'faiss-flat(QPS)', 'faiss-flat(R)', 'annoy(QPS)', 'annoy(R)', 'CAKES(QPS)', 'CAKES(R)']\n",
    "algorithms = ['faiss-ivf-flat', 'faiss-flat', 'annoy', 'CAKES']\n",
    "\n",
    "# Each dataset gets its own table \n",
    "for (dataset, dataset_df) in df.groupby('dataset'): \n",
    "    print(dataset)\n",
    "    # For each dataset, we show QPS and recall for each algorithm at each scale from 2**0 through 2**9\n",
    "    results_table = np.zeros((10, 2*len(algorithms)+1))\n",
    "\n",
    "    # We separate by scale so that at each scale, we can determine which of the 5 CAKES algorithms was best\n",
    "    for index, (scale, scale_df) in enumerate(dataset_df.groupby('scale')): \n",
    "\n",
    "        # We separate between CAKES and non-CAKES algorithms \n",
    "        for (cakes_bool, alg_df) in scale_df.groupby('cakes_alg'): \n",
    "            results_table[index][0] = scale\n",
    "            if cakes_bool: \n",
    "                max_throughput = alg_df['throughput'].max()\n",
    "                recall = alg_df['recall'].max()\n",
    "                results_table[index][7] = max_throughput\n",
    "                results_table[index][8] = recall\n",
    "                \n",
    "            else: \n",
    "                alg_df.sort_values(by='algorithm', key=lambda col: col.str.len(), inplace = True)\n",
    "                for i, (_, row) in enumerate(alg_df.iterrows()): \n",
    "                    results_table[index][2*i+1] = row.throughput\n",
    "\n",
    "                    results_table[index][2*i+2] = row.recall\n",
    "\n",
    "                \n",
    "    new_df = pd.DataFrame(data=results_table, columns=columns)\n",
    "    print(new_df.to_latex(header = columns, \n",
    "            index = False, \n",
    "            float_format = \"{:.3f}\".format ))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8151629-47f9-4150-9fed-3bdaf81fecc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcf66be-7066-492e-b87a-5d75610751ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
